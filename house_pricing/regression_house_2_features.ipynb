{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前言\n",
    "\n",
    "自从上次试着用最基础的线性回归训练一个有80个特征的数据集，梯度爆炸之后，今天拿一个简单到不能再简单的数据集试试能不能成功收敛。途中我们又会遇到什么问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "来自吴恩达机器学习课程第二周的课后练习。原本是txt文件，我通过下面三行代码把数据集另存为了csv，可以在这里[下载](https://github.com/linguoguo/data_science/blob/master/house_pricing/data/house_2_features.csv)。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"ex1data2.txt\",delimiter=',')\n",
    "df.columns=['size','bedroom','price']\n",
    "df.to_csv('house_simple.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据没有分训练集和测试集，房子的特征只有面积和房间数两个。\n",
    "我们将通过`pandas`库读取并处理数据 \n",
    "\n",
    "导入这里需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import d2lzh as d2l\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/house/house_2_features.csv' ,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2400</td>\n",
       "      <td>3</td>\n",
       "      <td>369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1416</td>\n",
       "      <td>2</td>\n",
       "      <td>232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000</td>\n",
       "      <td>4</td>\n",
       "      <td>539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>4</td>\n",
       "      <td>299900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   size  bedroom   price\n",
       "0  1600        3  329900\n",
       "1  2400        3  369000\n",
       "2  1416        2  232000\n",
       "3  3000        4  539900\n",
       "4  1985        4  299900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理数据集\n",
    "\n",
    "我们对连续数值的特征做`标准化（standardization)`：设该特征在整个数据集上的均值为$\\mu$，标准差为$\\sigma$。那么，我们可以将该特征的每个值先减去$\\mu$再除以$\\sigma$得到标准化后的每个特征值。对于缺失的特征值，我们将其替换成该特征的均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "\n",
    "data.fillna(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化后，每个特征的均值变为0，所以可以直接用0来替换缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.495977</td>\n",
       "      <td>-0.226166</td>\n",
       "      <td>-0.073110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.499874</td>\n",
       "      <td>-0.226166</td>\n",
       "      <td>0.236953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.725023</td>\n",
       "      <td>-1.526618</td>\n",
       "      <td>-0.849457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.246762</td>\n",
       "      <td>1.074287</td>\n",
       "      <td>1.592190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016724</td>\n",
       "      <td>1.074287</td>\n",
       "      <td>-0.311010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size   bedroom     price\n",
       "0 -0.495977 -0.226166 -0.073110\n",
       "1  0.499874 -0.226166  0.236953\n",
       "2 -0.725023 -1.526618 -0.849457\n",
       "3  1.246762  1.074287  1.592190\n",
       "4 -0.016724  1.074287 -0.311010"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把数据集分成两部分，训练集和测试集，并通过`values`属性得到NumPy格式的数据，并转成`NDArray`方便后面的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=36\n",
    "train_features = nd.array(data[['size','bedroom']][:n_train].values)\n",
    "test_features = nd.array(data[['size','bedroom']][n_train:].values)\n",
    "train_labels = nd.array(data.price[:n_train].values).reshape((-1, 1))\n",
    "test_labels = nd.array(data.price[n_train:].values).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.4959771  -0.22616564]\n",
       " [ 0.4998739  -0.22616564]\n",
       " [-0.72502285 -1.526618  ]]\n",
       "<NDArray 3x2 @cpu(0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型\n",
    "\n",
    "我们使用一个基本的线性回归模型和平方损失函数来训练模型。 关于更多gluon使用的步骤请参考这里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gloss.L2Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化算法\n",
    "\n",
    "创建一个`Trainer`实例，并指定学习率为0.03的小批量随机梯度下降（`sgd`）为优化算法。该优化算法将用来迭代`net`实例所有通过`add`函数嵌套的层所包含的全部参数。这些参数可以通过`collect_params`函数获取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "随机读取包含batch_size个数据样本的小批量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "train_iter = gdata.DataLoader(gdata.ArrayDataset(train_features, train_labels), batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.246766\n",
      "epoch 2, loss: 0.175986\n",
      "epoch 3, loss: 0.154656\n",
      "epoch 4, loss: 0.145171\n",
      "epoch 5, loss: 0.139558\n",
      "epoch 6, loss: 0.135769\n",
      "epoch 7, loss: 0.133386\n",
      "epoch 8, loss: 0.131887\n",
      "epoch 9, loss: 0.131060\n",
      "epoch 10, loss: 0.130636\n",
      "epoch 11, loss: 0.130462\n",
      "epoch 12, loss: 0.130103\n",
      "epoch 13, loss: 0.130018\n",
      "epoch 14, loss: 0.129933\n",
      "epoch 15, loss: 0.129811\n",
      "epoch 16, loss: 0.129775\n",
      "epoch 17, loss: 0.129756\n",
      "epoch 18, loss: 0.129881\n",
      "epoch 19, loss: 0.129783\n",
      "epoch 20, loss: 0.129748\n",
      "epoch 21, loss: 0.129793\n",
      "epoch 22, loss: 0.129718\n",
      "epoch 23, loss: 0.129762\n",
      "epoch 24, loss: 0.129740\n",
      "epoch 25, loss: 0.129720\n",
      "epoch 26, loss: 0.129723\n",
      "epoch 27, loss: 0.129789\n",
      "epoch 28, loss: 0.129730\n",
      "epoch 29, loss: 0.129753\n",
      "epoch 30, loss: 0.129713\n",
      "epoch 31, loss: 0.129727\n",
      "epoch 32, loss: 0.129721\n",
      "epoch 33, loss: 0.129731\n",
      "epoch 34, loss: 0.129759\n",
      "epoch 35, loss: 0.129845\n",
      "epoch 36, loss: 0.129771\n",
      "epoch 37, loss: 0.129713\n",
      "epoch 38, loss: 0.129727\n",
      "epoch 39, loss: 0.129765\n",
      "epoch 40, loss: 0.129871\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in train_iter:\n",
    "        with autograd.record():\n",
    "            l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "    l = loss(net(train_features), train_labels)\n",
    "    print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后记\n",
    "暂时看训练是能收敛的，损失也比上次少很多很多。下次我们再看几个问题：\n",
    "+ 怎么算测试集的房价\n",
    "+ 有没有过拟\n",
    "+ 损失函数的结果怎么看，是大还是小\n",
    "\n",
    "新手村的小伙伴们，你们有什么看法呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "书接上一回 我们训练了一个线性回归模型，数据集为有两个特征，46个样本的房价预测。\n",
    "# 预测结果\n",
    "怎么算测试集的房价，我昨天脑子秀逗了，果然抄代码一时爽，一直抄代码一直爽，爽到后面的代码都没有看了！午夜梦回，突然想起，我当时是怎么算的损失函数？\n",
    "我开心地去看看结果，好像有那么一丢丢大了点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1614004]\n"
     ]
    }
   ],
   "source": [
    "y_predit=net(test_features)\n",
    "l = loss(y_predit, test_labels)\n",
    "print(l.mean().asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 怎么看损失函数\n",
    "我都不知道损失函数的取值是多少，知道那么多种损失函数有什么意义？兹 傲娇脸\n",
    "上网找不到资料就自己看看吧，先看看数据集的取值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>4.600000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-9.171408e-17</td>\n",
       "      <td>1.339508e-16</td>\n",
       "      <td>-4.344351e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.427098e+00</td>\n",
       "      <td>-2.827070e+00</td>\n",
       "      <td>-1.341910e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.082178e-01</td>\n",
       "      <td>-2.261656e-01</td>\n",
       "      <td>-7.075102e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.598774e-01</td>\n",
       "      <td>-2.261656e-01</td>\n",
       "      <td>-3.110103e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.560979e-01</td>\n",
       "      <td>1.074287e+00</td>\n",
       "      <td>2.359614e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.086597e+00</td>\n",
       "      <td>2.374739e+00</td>\n",
       "      <td>2.860989e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               size       bedroom         price\n",
       "count  4.600000e+01  4.600000e+01  4.600000e+01\n",
       "mean  -9.171408e-17  1.339508e-16 -4.344351e-17\n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00\n",
       "min   -1.427098e+00 -2.827070e+00 -1.341910e+00\n",
       "25%   -7.082178e-01 -2.261656e-01 -7.075102e-01\n",
       "50%   -1.598774e-01 -2.261656e-01 -3.110103e-01\n",
       "75%    3.560979e-01  1.074287e+00  2.359614e-01\n",
       "max    3.086597e+00  2.374739e+00  2.860989e+00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.17的损失函数跟1的方差比好像不是很大。。。直到这里，我们的初步看法都是“好像”，“差不多”，“大概”。。。 作为一个未来的大神，怎么可以对自己要求这么低。\n",
    "\n",
    "我们把结果打印出来看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.0466327]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[0.20947975]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[1.6643525]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[2.6858356]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[-0.41330725]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[0.24514496]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[0.23298769]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[-0.332606]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[-0.07311028]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[0.34264287]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[-0.19919726]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[0.7266256]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[-0.31814724]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[-0.8913743]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[-1.2626102]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[-1.297945]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[-0.31101027]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[-0.12339576]\n",
      "<NDArray 1 @cpu(0)>\n",
      "\n",
      "[-0.7899822]\n",
      "<NDArray 1 @cpu(0)> \n",
      "[-0.8878077]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(test_labels[i],y_predit[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看前三个对比也差太远了吧，按百分比再算一遍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-349.2121] %\n",
      "[-61.374203] %\n",
      "[159.31302] %\n",
      "[242.75688] %\n",
      "[568.6658] %\n",
      "[464.7769] %\n",
      "[-180.17665] %\n",
      "[-2.7985537] %\n",
      "[60.32421] %\n",
      "[-12.383257] %\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print( ((test_labels[i]-y_predit[i])*100/test_labels[i]).asnumpy(),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我要用这个数据看一个房子值不值得买，会亏到没裤衩吧。最大差5倍，我自闭了，这个结果肯定是不行的！看看每平方均价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>bedroom</th>\n",
       "      <th>price</th>\n",
       "      <th>price_size</th>\n",
       "      <th>price_bedroom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-9.171408e-17</td>\n",
       "      <td>1.339508e-16</td>\n",
       "      <td>-4.344351e-17</td>\n",
       "      <td>2.387465</td>\n",
       "      <td>0.450725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.833545</td>\n",
       "      <td>2.856655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.427098e+00</td>\n",
       "      <td>-2.827070e+00</td>\n",
       "      <td>-1.341910e+00</td>\n",
       "      <td>-3.711958</td>\n",
       "      <td>-8.442439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.082178e-01</td>\n",
       "      <td>-2.261656e-01</td>\n",
       "      <td>-7.075102e-01</td>\n",
       "      <td>0.341222</td>\n",
       "      <td>-0.286206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.598774e-01</td>\n",
       "      <td>-2.261656e-01</td>\n",
       "      <td>-3.110103e-01</td>\n",
       "      <td>0.969627</td>\n",
       "      <td>0.455811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.560979e-01</td>\n",
       "      <td>1.074287e+00</td>\n",
       "      <td>2.359614e-01</td>\n",
       "      <td>1.594585</td>\n",
       "      <td>1.826074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.086597e+00</td>\n",
       "      <td>2.374739e+00</td>\n",
       "      <td>2.860989e+00</td>\n",
       "      <td>32.073789</td>\n",
       "      <td>4.913015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               size       bedroom         price  price_size  price_bedroom\n",
       "count  4.600000e+01  4.600000e+01  4.600000e+01   46.000000      46.000000\n",
       "mean  -9.171408e-17  1.339508e-16 -4.344351e-17    2.387465       0.450725\n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00    5.833545       2.856655\n",
       "min   -1.427098e+00 -2.827070e+00 -1.341910e+00   -3.711958      -8.442439\n",
       "25%   -7.082178e-01 -2.261656e-01 -7.075102e-01    0.341222      -0.286206\n",
       "50%   -1.598774e-01 -2.261656e-01 -3.110103e-01    0.969627       0.455811\n",
       "75%    3.560979e-01  1.074287e+00  2.359614e-01    1.594585       1.826074\n",
       "max    3.086597e+00  2.374739e+00  2.860989e+00   32.073789       4.913015"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['price_size']=data['price']/data['size']\n",
    "data['price_bedroom']=data['price']/data['bedroom']\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看每平方价钱，75%小于1.59，然而最大的数去到32，有点大得离谱了，可能这个数据集来自不同地方或者不同类型的房子，也可能有输入错误？我们现在怎么办？吴恩达第六周的课程好像可以给我们答案，我们且看下回分解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新加入两个特征训练一下，第一次不小心就出现Nan了，果然对学习率很敏感啊，不小心就梯度爆炸了，此处可参考这篇博文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 2190.526367\n",
      "epoch 2, loss: 710725.562500\n",
      "epoch 3, loss: 284985280.000000\n",
      "epoch 4, loss: 227231154176.000000\n",
      "epoch 5, loss: 85445782274048.000000\n",
      "epoch 6, loss: 87628233465397248.000000\n",
      "epoch 7, loss: 37323010165786542080.000000\n",
      "epoch 8, loss: 4764028720072496250880.000000\n",
      "epoch 9, loss: 6082304267000688419012608.000000\n",
      "epoch 10, loss: 6613091637294114079303008256.000000\n",
      "epoch 11, loss: 2311386075767621512855384227840.000000\n",
      "epoch 12, loss: 909418451767419360324547522854912.000000\n",
      "epoch 13, loss: 287194146490916168776753067186978816.000000\n",
      "epoch 14, loss: inf\n",
      "epoch 15, loss: inf\n",
      "epoch 16, loss: inf\n",
      "epoch 17, loss: inf\n",
      "epoch 18, loss: inf\n",
      "epoch 19, loss: inf\n",
      "epoch 20, loss: inf\n",
      "epoch 21, loss: inf\n",
      "epoch 22, loss: inf\n",
      "epoch 23, loss: inf\n",
      "epoch 24, loss: inf\n",
      "epoch 25, loss: inf\n",
      "epoch 26, loss: inf\n",
      "epoch 27, loss: nan\n",
      "epoch 28, loss: nan\n",
      "epoch 29, loss: nan\n",
      "epoch 30, loss: nan\n",
      "epoch 31, loss: nan\n",
      "epoch 32, loss: nan\n",
      "epoch 33, loss: nan\n",
      "epoch 34, loss: nan\n",
      "epoch 35, loss: nan\n",
      "epoch 36, loss: nan\n",
      "epoch 37, loss: nan\n",
      "epoch 38, loss: nan\n",
      "epoch 39, loss: nan\n",
      "epoch 40, loss: nan\n"
     ]
    }
   ],
   "source": [
    "n_train=36\n",
    "train_features = nd.array(data[['size','bedroom','price_size','price_bedroom']][:n_train].values)\n",
    "test_features = nd.array(data[['size','bedroom','price_size','price_bedroom']][n_train:].values)\n",
    "train_labels = nd.array(data.price[:n_train].values).reshape((-1, 1))\n",
    "test_labels = nd.array(data.price[n_train:].values).reshape((-1, 1))\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(1))\n",
    "\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "\n",
    "loss = gloss.L2Loss()\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03})\n",
    "\n",
    "batch_size=2\n",
    "train_iter = gdata.DataLoader(gdata.ArrayDataset(train_features, train_labels), batch_size, shuffle=True)\n",
    "num_epochs = 40\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in train_iter:\n",
    "        with autograd.record():\n",
    "            l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "    l = loss(net(train_features), train_labels)\n",
    "    print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.280175\n",
      "epoch 2, loss: 0.252596\n",
      "epoch 3, loss: 0.247836\n",
      "epoch 4, loss: 3.694590\n",
      "epoch 5, loss: 0.971740\n",
      "epoch 6, loss: 0.563291\n",
      "epoch 7, loss: 2.774067\n",
      "epoch 8, loss: 0.801260\n",
      "epoch 9, loss: 0.179848\n",
      "epoch 10, loss: 0.149339\n",
      "epoch 11, loss: 1.921999\n",
      "epoch 12, loss: 0.128801\n",
      "epoch 13, loss: 0.215510\n",
      "epoch 14, loss: 0.193499\n",
      "epoch 15, loss: 0.514674\n",
      "epoch 16, loss: 0.250536\n",
      "epoch 17, loss: 0.112822\n",
      "epoch 18, loss: 0.170746\n",
      "epoch 19, loss: 0.232429\n",
      "epoch 20, loss: 0.146247\n",
      "epoch 21, loss: 1.763635\n",
      "epoch 22, loss: 1.205917\n",
      "epoch 23, loss: 0.113654\n",
      "epoch 24, loss: 0.110538\n",
      "epoch 25, loss: 0.166103\n",
      "epoch 26, loss: 0.147857\n",
      "epoch 27, loss: 0.178377\n",
      "epoch 28, loss: 0.152319\n",
      "epoch 29, loss: 0.131106\n",
      "epoch 30, loss: 0.399766\n",
      "epoch 31, loss: 0.109490\n",
      "epoch 32, loss: 0.546786\n",
      "epoch 33, loss: 0.150535\n",
      "epoch 34, loss: 0.521338\n",
      "epoch 35, loss: 2.954722\n",
      "epoch 36, loss: 0.106273\n",
      "epoch 37, loss: 0.139209\n",
      "epoch 38, loss: 0.422830\n",
      "epoch 39, loss: 0.115425\n",
      "epoch 40, loss: 0.105446\n"
     ]
    }
   ],
   "source": [
    "n_train=36\n",
    "train_features = nd.array(data[['size','bedroom','price_size','price_bedroom']][:n_train].values)\n",
    "test_features = nd.array(data[['size','bedroom','price_size','price_bedroom']][n_train:].values)\n",
    "train_labels = nd.array(data.price[:n_train].values).reshape((-1, 1))\n",
    "test_labels = nd.array(data.price[n_train:].values).reshape((-1, 1))\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(1))\n",
    "\n",
    "net.initialize(init.Normal(sigma=0.01))\n",
    "\n",
    "loss = gloss.L2Loss()\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.01})\n",
    "\n",
    "batch_size=2\n",
    "train_iter = gdata.DataLoader(gdata.ArrayDataset(train_features, train_labels), batch_size, shuffle=True)\n",
    "num_epochs = 40\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in train_iter:\n",
    "        with autograd.record():\n",
    "            l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "    l = loss(net(train_features), train_labels)\n",
    "    print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里看到loss有时会突然变大，可以看出我们已经在最优解左右徘徊，可以了，我们测试一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1441034]\n"
     ]
    }
   ],
   "source": [
    "y_predit=net(test_features)\n",
    "l = loss(y_predit, test_labels)\n",
    "print(l.mean().asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过拟合还是欠拟合？\n",
    "测试集的0.144 和训练集的0.105差不是很多，但是结果不算好。直觉告诉我应该是欠拟合，因为这里是偏差比较大的。发现一个写得不错的文章：[神经网络:欠拟合和过拟合](https://www.jianshu.com/p/9b6b0d6d3bd0) 还有一篇关于过度训练的[过拟合详解：监督学习中不准确的「常识」](https://www.jiqizhixin.com/articles/2019-01-25-23)\n",
    "最后关于欠拟合过拟合这件事，我还是不能只靠直觉，还是要用更专业的方法 [学习曲线——判断欠拟合还是过拟合](https://blog.csdn.net/geduo_feng/article/details/79547554)\n",
    "### 预告\n",
    "+ 明天我们再来看看怎么用mxnet写学习曲线。\n",
    "+ 看其它更好的算法\n",
    "+ 更多提取特征的方法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
